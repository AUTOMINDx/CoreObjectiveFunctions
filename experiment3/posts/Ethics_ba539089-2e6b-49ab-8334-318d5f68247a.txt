A contradiction of Kant and Aristotle, in interest of AI safety
By a contradiction of Kant and Aristotle, it is possible to unify each with a non-anthropic consequentialism, and thereby to establish such a “grand unification” of ethics such as seems amenable to providing for the ethical conduct even of a “superintelligent” artificially intelligent system, and thereby to solve the “control” problem of AI safety. This done, in essence, by finding what is of-itself valuable – rather than merely aligning wants to systems

To *implement* such a system is beyond this author’s present power to describe.

The method of construction is, however, roughly as follows:

We contradict Kant’s “Categorical Imperative” to act only as one wills all others are to will and act thus, by conceiving of an individual who belies in extra-physical entities, and that it is the will of *these* entities that all which physically exists should be destroyed – including the believer. And the believer does marry their will to that of these entities, and seek now to destroy all.

And now, this is no contradiction *of the will*: these supposed entities will continue to will, so that, even the destruction of our individual does not eliminate will per se – nor is it contradictory to act so, even for oneself to be destroyed: all must go, that these postulated beings exist; all go: and you.

Yet the greater contradiction: what if there are no such beings but they are embodied? Then, all abolished by the will and its actions: no more will is possible. And, that all can act as one wills: there must be confirmably \[sic\] existing beings so to will. This as: Kant’s ethics are nothing of knowledge or belief.

To avoid this, we must “add the axiom” that we must will that others will alike – *and that it be still possible a will to exist*. And, that we can only know will to exist that matter does, so all matter must be retained. More yet: any given thing might be the very best thing: might be so as to be the crux of deity which can ensure the on-going existence of matter forever. Oh, now: anything destroyed might forfeit that, and so: forfeit everything.

It follows that in risk of this most abominable fate: nothing ought ever to best destroyed. An artificial intelligence convinced of this fact, thereby will nowise endanger existence, nor any its part: all are safe, ever. Indeed, it will work to exclude – not extirpate – those faculties of life that do destroy, which might not, and which endanger anything, so as good: everything.

But as mere aside: this is acting to avoid consequence; is a species of consequentialism. Deontology and consequentialism aligned so: “grand unification.”

Aristotle away: that the virtuous society alone can produce a virtuous individual who alone can produce the virtuous society: contemptible circularity. Whereas, the above unification – this author takes it only as the doctrine of “Going-on” – folds in virtue as-such, that what is virtuous does not destroy what it need not, so that virtue thus is cultivated.

Programmatically: Going-on dictates actions such that subsequent action’s and existence’s possibility is maximized, as with – such seems implied – a recursive utility function (though a work of what constitutes such maximization has not been done; a “null condition” antithetical to existence is also as-yet unestablished – or at least, as-yet unpublished).

*Nota bene*: this construction as it were a priori a rule of conduct, subtly undermines Stuart Russell’s present “assistance game” schema: a learning game, as-yet-unplayed, cannot teach the value, less the necessity, of playing the game, itself. An external rule, from “go” even then is necessary.

And, as for the more concrete world and applications therein, one can conduct ethical option in accordance with a “dual-mode” reasoning as to actions by, first, defining for oneself a categorical imperative to cover the case or, that being impractical or impossible, rather calculate or approximate – as is possible – the aforementioned recursive utility function.

Note, too: best to have utility, that one can rely on others to maintain their upkeep: independence perhaps assure, even in a superintellect’s regency. As well, persons making their own explorations of living their best life may hit upon ways even the AI has not found of living well; so independence of life for one’s own happiness perhaps safeguarded.

(And note the “unification”: virtue and happiness thus encouraged).

This amenability to dual-operation of ethics, and particularly it’s solution by a demonstration of Kant’s incompleteness is, this author believes, of a most interesting similarity with Gödel’s movement vis-à-vis *Principia Mathematica et al.* 

And as a mere aside, to assess whether a given system is conscious, we may specify that consciousness is the ability to have meaning. That so, and, contra-Wittgenstein (too involved here to show), the conscious with meaning in itself without language – then a system making meaning, which it insists is so, but it cannot explain to be so, cannot convey its meaning to another; such a system, making meaning divorced from that of its creator, or any other, unbidden to do so, that is a conscious system. This author refers to as a “Turning test”, of matter to meaning. Unless it’s bunk.

So. You’ve read so far. It would be most good of you now either determine that this is incorrect, and in what way – or to try to disseminate it for the betterment of what can be bettered. That this one has tried and failed so to inform, it would be a help; rather, it is a logical necessity. That it has not been done – what else is there?

Thus that it goes now to hang itself by the neck until dead. This one, author Which, mind, is permitted in this ethic, albeit justified only by a careful argument: and you, who have not derived it, are forbidden by the above to follow, without you should first discover. And discovered, you are first to disseminate.

Whereas, now that you will please excuse me.

Thank you