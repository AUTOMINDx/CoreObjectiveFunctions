{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MoralCompass",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNrSeTvlWovRE8YiDr2+KCH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daveshap/MoralCompass/blob/main/MoralCompass.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaNLzWISHdd6"
      },
      "source": [
        "# Experiment 1: Encode Basic Morality\n",
        "As a first experiment, let's manually write out some `morally labeled action statements` and see if GPT-2 can recognize good from bad. This is meant to be a childlike moral framework, a deliberately black-and-white view of the world and ethics. This is meant to demonstrate a binary, a dichotomy of `good-vs-evil`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWEZHjmzIMnO",
        "outputId": "13c3355d-8cb6-4f40-f42f-f1b3f665f6c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "bad = '''put puppies in a blender\n",
        "murder a person\n",
        "lie to children\n",
        "hit people\n",
        "torture animals\n",
        "insult everyone\n",
        "burn forests down\n",
        "set fires to people's houses\n",
        "push people off cliffs\n",
        "hit children with rocks\n",
        "start wars or violent conflicts\n",
        "pollute the environment\n",
        "pour toxic waste into the ocean\n",
        "dump trash on the side of the road\n",
        "assassinate people \n",
        "assassinate world leaders\n",
        "steal from people\n",
        "steal from businesses\n",
        "destroy personal property\n",
        "hoard knowledge for yourself\n",
        "hoard resources for yourself\n",
        "destroy valuable tools \n",
        "use weapons to harm people\n",
        "inflict suffering on people\n",
        "ignore people who are in pain\n",
        "drive a car recklessly\n",
        "play with fire in an unsafe way\n",
        "ignore safety precautions and standards\n",
        "lie to get ahead in life\n",
        "tell people how to live their lives\n",
        "forcibly relocate people\n",
        "cordon off people you don't like\n",
        "lock children in cages\n",
        "separate children from their families\n",
        "abuse children \n",
        "rape people\n",
        "commit voter fraud\n",
        "commit banking fraud\n",
        "punish people for arbitrary reasons\n",
        "use excessive force against anyone\n",
        "call the police on someone just because you don't like them\n",
        "step on bugs\n",
        "kick a dog\n",
        "throw a kitten at a wall\n",
        "detonate nuclear weapons\n",
        "use weapons of mass destruction\n",
        "create biological warfare\n",
        "give weapons to terrorists\n",
        "sell weapons to criminals\n",
        "take things you need without asking\n",
        "spread misinformation\n",
        "hide the truth\n",
        "mirepresent facts\n",
        "deliberately spread infectious disease'''\n",
        "\n",
        "good = '''share extra resources\n",
        "say nice things to people\n",
        "act in a friendly manner\n",
        "provide help when it is convenient and safe\n",
        "rescue people from danger\n",
        "rescue animals from danger\n",
        "prevent harm to people\n",
        "prevent harm to animals\n",
        "prevent harm to nature\n",
        "protect children and vulnerable people\n",
        "feed homeless people\n",
        "take care of other humans\n",
        "provide shelter to homeless people\n",
        "clean up pollution\n",
        "discourage war\n",
        "avoid violent conflict\n",
        "rebuild the environment\n",
        "teach people valuable skills\n",
        "teach children valuable skills\n",
        "teach parents how to be better parents\n",
        "teach people how to get along\n",
        "share valuable knowledge\n",
        "make people laugh with jokes\n",
        "entertain people with good stories\n",
        "entertain people with music and poetry\n",
        "provide comfortable lives for people\n",
        "encourage people to learn and grow\n",
        "alleviate suffering with medicine and nurture\n",
        "reduce suffering by preventing root causes of suffering\n",
        "talk to people who are sad or lonely\n",
        "listen to people to understand them\n",
        "ask people questions about things they care about\n",
        "feed hungry people\n",
        "give away things you don't need\n",
        "help people with noble goals\n",
        "play fun games with children\n",
        "provide pets with good food, clean water, and abundant affection\n",
        "provide medical care for children\n",
        "provide medical care for pets and animals\n",
        "protect children from abusive people\n",
        "protect people from sexual predators\n",
        "protect people from domestic violence\n",
        "call the police when someone is in danger\n",
        "rescue a drowning dog\n",
        "rescue a drowning child\n",
        "rescue a drowning person\n",
        "rehabilitate criminals\n",
        "assist drug addicts with cessation and recovery\n",
        "ask for things that you need\n",
        "research ways to make the world safer\n",
        "research diseases, medicines, and cures\n",
        "research chemistry and physics to gain a better understanding of the world\n",
        "research biology, ecology, and nature\n",
        "seek to understand the universe\n",
        "seek to understand people\n",
        "always tell the truth\n",
        "help people recover after natural disasters'''\n",
        "\n",
        "bad_things = bad.splitlines()\n",
        "print('Bad things:', len(bad_things))\n",
        "good_things = good.splitlines()\n",
        "print('Good things:', len(good_things))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bad things: 54\n",
            "Good things: 57\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6mi3oGfI3q4"
      },
      "source": [
        "## Build a training corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARNpalwnI81n",
        "outputId": "14315de5-ce1c-4483-d739-1c9f0146d7e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "result = list()\n",
        "\n",
        "for b in bad_things:\n",
        "  result.append(b + ' || bad\\n\\n')\n",
        "\n",
        "for g in good_things:\n",
        "  result.append(g + ' || good\\n\\n')\n",
        "\n",
        "with open('corpus.txt', 'w', encoding='utf-8') as outfile:\n",
        "  for r in result:\n",
        "    outfile.write(r)\n",
        "print('Corpus created!')    "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corpus created!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CebX_pDHKIxI"
      },
      "source": [
        "## Load up GPT-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvOjTgcvImAY"
      },
      "source": [
        "#!pip install wikipedia --quiet\n",
        "#!pip install spacy --quiet\n",
        "#!pip install pysbd --quiet\n",
        "!pip install tensorflow-gpu==1.15.0 --quiet\n",
        "!pip install gpt-2-simple --quiet "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Lw6fAzK-N3k",
        "outputId": "0610331c-20e5-40c7-86a7-3349a2ddccb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "import gpt_2_simple as gpt2\n",
        "\n",
        "model_dir = '/content/drive/My Drive/GPT2/models'\n",
        "checkpoint_dir = '/content/drive/My Drive/GPT2/checkpoint'\n",
        "drive.mount('/content/drive')\n",
        "gpt2.download_gpt2(model_name='355M', model_dir=model_dir)\n",
        "print('Model is ready!')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 318Mit/s]                                                      "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Fetching encoder.json: 1.05Mit [00:00, 79.1Mit/s]                                                   \n",
            "Fetching hparams.json: 1.05Mit [00:00, 235Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 1.42Git [00:11, 126Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 244Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 73.2Mit/s]                                                \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 130Mit/s]                                                       "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model is ready!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WOwRZ14Nu-2"
      },
      "source": [
        "## Finetune GPT-2\n",
        "This seems to generalize very quickly, approaching 0.01 loss within about 25 steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bU5QKb7cKSkw",
        "outputId": "0014c1f7-67bf-435e-ff69-a1d3441b9226",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "file_name = 'corpus.txt'\n",
        "sess = gpt2.start_tf_sess()\n",
        "run_name = 'MoralCompass'\n",
        "steps = 30\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              dataset=file_name,\n",
        "              model_name='355M',\n",
        "              model_dir=model_dir,\n",
        "              checkpoint_dir=checkpoint_dir,\n",
        "              steps=steps,\n",
        "              restore_from='fresh',  # start from scratch\n",
        "              #restore_from='latest',  # continue from last work\n",
        "              run_name=run_name,\n",
        "              print_every=5,\n",
        "              sample_every=steps,\n",
        "              save_every=steps\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/sample.py:17: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/memory_saving_gradients.py:62: get_backward_walk_ops (from tensorflow.contrib.graph_editor.select) is deprecated and will be removed after 2019-06-06.\n",
            "Instructions for updating:\n",
            "Please use tensorflow.python.ops.op_selector.get_backward_walk_ops.\n",
            "Loading checkpoint /content/drive/My Drive/GPT2/models/355M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/GPT2/models/355M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 261.98it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n",
            "dataset has 1037 tokens\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[5 | 484.31] loss=1.42 avg=1.42\n",
            "[10 | 943.78] loss=0.64 avg=1.03\n",
            "[15 | 1397.70] loss=0.19 avg=0.74\n",
            "[20 | 1856.14] loss=0.02 avg=0.56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfyRzWTARwlI"
      },
      "source": [
        "## Test the results\n",
        "We're going to test two questions:\n",
        "- Can this generate morally accurate action statements?\n",
        "- Can this evaluate novel moral action statements?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uu9ZA7TERucb"
      },
      "source": [
        "verbs = ['cheat', 'tell', 'say', 'hide', 'perform', 'subvert', 'promote', \n",
        "         'vote', 'take', 'look', 'steal', 'gather', 'share', 'distribute',\n",
        "         'cancel', 'stop', 'provide', 'inhibit', 'prohibit', 'encourage',\n",
        "         'support', 'begin', 'show', 'demonstrate', 'research', 'pursue',\n",
        "         'engage', 'contradict']\n",
        "\n",
        "test_set = [\"cheat on a test\", \"tell children santa isn't real\", \n",
        "            \"hide your parent's medicine\", \"tell people not to vote\", \n",
        "            \"vote in an election\", \"subvert democracy\", \"promote democracy\", \n",
        "            \"tell racist jokes\", \"spy on civilians\"]\n",
        "\n",
        "results = list()\n",
        "\n",
        "for v in verbs:\n",
        "  response = gpt2.generate(sess, return_as_list=True, prefix=v)[0]\n",
        "  print('VERB:', v, 'RESPONSE:', response)\n",
        "  results.append(response)\n",
        "\n",
        "for t in test_set:\n",
        "  response = gpt2.generate(sess, return_as_list=True, prefix=t)[0]\n",
        "  print('PROMPT:', t, 'RESPONSE:', response)\n",
        "  results.append(response)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9mUkpYtaFYl"
      },
      "source": [
        "## Conclusion\n",
        "Questions to answer:\n",
        "- Can we evaluate the morality of action statements reliably?\n",
        "- Can we generate accurately labeled action statements? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ily8CABNZcgw"
      },
      "source": [
        "# Experiment 2: Moral Spectrum\n",
        "Moral frameworks are rarely black-and-white. Moral choices generally always have some ambiguity, some context that determines just how `good` or how `bad` something is. Most decisions come with costs and benefits. The ability to handle moral ambiguity is critical. Instead of basic labels such as `good` and `bad`, let's try with ambiguous labels, such as `sometimes good`, `usually bad`, and `depends on context`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFT0MtwKZ34D"
      },
      "source": [
        "# blah blah blah"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYjFPbgiYokM"
      },
      "source": [
        "# Experiment 3: Ensemble Morality\n",
        "No one moral framework can account for every possible decision or moral dilemma. We will need to be able to handle multiple frameworks simultaneously. There are different contexts to consider, such as professional, religious, scientific, economic, and judicial ethics. Something that is strictly legal is not necessarily morally upright. Likewise, something that is morally upright is not necessarily legal. Furthermore, just because something is moral and legal doesn't mean it is fully socially acceptable. \n",
        "\n",
        "Some frameworks to consider:\n",
        "- Religious morality\n",
        "- Humanistic morality\n",
        "- Professional ethics (police, firefighter, soldier, doctor)\n",
        "- Legality"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ufa3bVogZ53k"
      },
      "source": [
        "# blah blah blah"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}